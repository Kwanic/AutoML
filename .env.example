# ============================================================================
# AI-Enhanced ML Pipeline Configuration
# ============================================================================
# This file contains all configuration parameters for the pipeline.
# Copy this file to .env and adjust the values according to your needs.
#
# Usage:
#   cp .env.example .env
#   # Edit .env with your settings
#   python main.py  # or bash run.sh
# ============================================================================

# ============================================================================
# OpenAI API Configuration (REQUIRED)
# ============================================================================

# Your OpenAI API key - REQUIRED for AI code generation and literature review
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-api-key-here

# OpenAI API base URL (usually no need to change)
# Default: https://api.openai.com/v1
OPENAI_BASE_URL=https://api.openai.com/v1

# OpenAI model to use for code generation and debugging
# Options: gpt-4, gpt-4-turbo, gpt-5, etc.
# Default: gpt-5
OPENAI_MODEL=gpt-5


# ============================================================================
# Bayesian Optimization Parameters
# ============================================================================

# Maximum number of Bayesian Optimization trials
# Higher values = better optimization but more API calls and time
# Recommended: 20-50 for quick experiments, 40-100 for production
# Default: 40
MAX_BO_TRIALS=40

# Number of training samples to use for Bayesian Optimization
# Options:
#   - "ALL": Use entire training dataset (best performance, slower)
#   - Integer (e.g., 5000): Use random subset (faster, still effective)
# Recommended: 5000-10000 for large datasets, "ALL" for small datasets
# Default: ALL
BO_SAMPLE_NUM=ALL

# Maximum number of GPT debugging attempts when training errors occur
# Each debugging attempt uses 1 API call
# Recommended: 3-5 for most cases
# Default: 4
DEBUG_CHANCES=4


# ============================================================================
# Pipeline Execution Parameters
# ============================================================================

# Number of complete pipeline runs when using run.sh
# Each run generates a new model with different random initialization
# Useful for statistical analysis and reproducibility studies
# Default: 8
NUM_RUNS=8

# Skip AI-powered literature review before code generation
# Options: True (skip), False (perform literature review)
# Literature review adds 1-2 extra API calls but may improve model selection
# Recommended: True for quick experiments, False for research projects
# Default: True
SKIP_LITERATURE_REVIEW=True


# ============================================================================
# Dataset Information (for GPT Context)
# ============================================================================

# Dataset name - used to provide context to GPT for better model selection
# This helps GPT understand the domain and suggest appropriate architectures
# Example: "MIT-BIH Arrhythmia Database", "CIFAR-10", "Custom Sensor Data"
DATASET_NAME=MIT-BIH Arrhythmia Database

# Dataset source URL or description
# Provides additional context for GPT about data provenance
# Example: "https://physionet.org/content/mitdb/1.0.0/", "Kaggle", "Internal"
DATASET_SOURCE=https://physionet.org/content/mitdb/1.0.0/

# Data folder path (relative to project root)
# The pipeline will load data from this directory
# Default: dataset1
DATA_FOLDER=dataset1


# ============================================================================
# System Configuration
# ============================================================================

# Operating system type - helps GPT generate OS-optimized code
# Options: Linux, Windows, Mac
# Default: Linux
OS_TYPE=Linux


# ============================================================================
# Advanced Settings (Optional)
# ============================================================================

# Random seed for reproducibility (uncomment to use)
# RANDOM_SEED=42

# GPU device ID (uncomment to specify GPU)
# CUDA_VISIBLE_DEVICES=0

# Maximum model size in KB (used for size penalty in BO)
# Default: 256
# MAX_MODEL_SIZE_KB=256

# Logging level (DEBUG, INFO, WARNING, ERROR)
# Default: INFO
# LOG_LEVEL=INFO


# ============================================================================
# Notes
# ============================================================================
#
# Cost Estimation (approximate):
# - Each BO trial: 0 API calls (only training, no GPT)
# - Code generation: 1-2 API calls (1 for code, +1 if literature review)
# - Debugging: 0-DEBUG_CHANCES API calls (only if errors occur)
#
# Total API calls per run â‰ˆ 1-2 (code gen) + 0-4 (debugging if needed)
#
# Memory Usage:
# - BO_SAMPLE_NUM controls training memory usage
# - Larger samples = better models but more GPU/RAM needed
# - Use "ALL" only if you have sufficient GPU memory
#
# Performance Tips:
# - Start with BO_SAMPLE_NUM=5000, increase if accuracy is poor
# - Use MAX_BO_TRIALS=20 for quick tests, 40+ for final models
# - Enable SKIP_LITERATURE_REVIEW=False for research/publication
# - Set NUM_RUNS=1 for single experiments, 5-10 for statistics
#
# ============================================================================
